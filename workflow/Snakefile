# copyright 2022 nicholas.waglechner@sinaihealth.ca
import sys
import os
import pandas as pd
import glob

# add to command line to be explicit --configfile: ./config/config.yaml"
if len(config) == 0:
    exit('no configfile specified: use --configfile [file]')

config_path = sys.argv[sys.argv.index('--configfile') + 1]
print(f"using config: {config_path}", file=sys.stderr)

container: "docker://continuumio/miniconda3:4.9.2"

"""
from https://snakemake.readthedocs.io/en/v5.22.1/snakefiles/configuration.html#validation
""" # noqa
# validate(config, "config.schema.yaml")
# validate(samples, "samples.schema.yaml")

# TODO -- from
"""
https://charlesreid1.github.io/building-snakemake-command-line-wrappers-for-workflows.html
""" # noqa

exec_dir = os.getcwd()
res = config['results_dir']

include: "common.smk"

samples = get_samples()
sample_names = samples.keys()
# TODO this is kind of lazy, and could use some more checks to ensure there are
# paired R1 and R2 for each sample
short_sample_names = [n for n in sample_names if len(samples[n]['MISEQ']['R1']) > 0]
long_sample_names = [n for n in sample_names if len(samples[n]['MINION']) > 0]
short_only_sample_names = [
    n for n in short_sample_names if n not in long_sample_names
]
long_only_sample_names = [
    n for n in long_sample_names if n not in short_sample_names
]
both_samples = [
    n for n in sample_names if 
    n in short_sample_names and 
    n in long_sample_names
]
# sample_names = list(sample_names)[:20]
print("short samples:", short_sample_names, file=sys.stderr)
print("short only samples:", short_only_sample_names, file=sys.stderr)
print("long samples:", long_sample_names, file=sys.stderr)
print("long only samples:", long_only_sample_names, file=sys.stderr)
print("both sample names:", both_samples, file=sys.stderr)

filt_short_samples = list(short_sample_names)
filtered_short_samples = config['exclude_short_samples']
for name in filtered_short_samples:
    try:
        filt_short_samples.remove(name)
    except Exception as e:
        print(
            f"SHORT - tried to_exclude {name}, not found in sample_sheet",
            file=sys.stderr
        )
filt_long_samples = list(long_sample_names)
filtered_long_samples = config['exclude_long_samples']
for name in filtered_long_samples:
    try:
        filt_long_samples.remove(name)
    except Exception as e:
        print(
            f"LONG - tried to exclude {name}, not found in sample_sheet",
            file=sys.stderr
        )
print('Including {} isolates (from original {} isolates)'.format(
    len(filt_short_samples + filt_long_samples), 
    len(short_sample_names + long_sample_names)
))

# medaka parsing to turn off
if config['dflye_medaka'] < 1:
    config['_DFLYE_MEDAKA'] = ""
else:
    config['_DFLYE_MEDAKA'] = f" --medaka {config['dflye_medaka']} " \
        f"--model {config['dflye_medaka_model']} " \
        f"--medaka_opts \'{config['dflye_medaka_opts']}\' "

# external data rules + GATK initialization
include: "stage0.smk"

# Illumina-QC pipeline
include: "stage1.smk"
# # variant calling
include: "stage2_short.smk"
include: "stage2_long.smk"
# # variant counting
include: "stage3_short_andor_long.smk"
# include: "stage3_long.smk"
# include: "SNP_counts.smk"

rule all:
# Rule "all" default catches output of other rules as input in order to
# simplify running the workflow
# - add target rules here as they are implemented

rule stage1:
    input:
        ###############
        # STAGE 1 - QC
        ###############
        f"{res}/QC_summary.csv"

rule stage1_all_outputs:
    input:
        # pre-trim QC
        expand(
            "{res}/{sample}/input/{R}_fastqc.html",
            res=res,
            sample=short_sample_names,
            R=["R1", "R2"],
        ),
        # trimmed input
        expand(
            "{res}/{s}/input/{read}.trim.fastq.gz",
            res=res,
            s=short_sample_names,
            read=["R1", "R2", "S1", "S2"],
        ),
        # post-trim QC
        expand(
            "{res}/{s}/input/{read}.trim_fastqc.data.txt",
            res=res,
            s=short_sample_names,
            read=["R1", "R2", "S1", "S2"],
        ),
        expand(
            "{res}/{s}/input/{read}_fastqc.data.txt",
            res=res,
            s=short_sample_names,
            read=["R1", "R2"],
        ),
        expand(
            "{res}/{s}/input/long_fastqc.data.txt",
            res=res,
            s=long_sample_names,
        ),
        # Kraken contamination, paired and single
        expand(
            "{res}/{sample}/input/kraken.trimmed.paired",
            res=res,
            sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/input/kraken.trimmed.single",
            res=res,
            sample=short_sample_names,
        ),
        # assembly with shovill
        expand(
            "{res}/{sample}/shovill_assembly/{sample}.shovill.contigs.fa",
            res=res,
            sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/dflye/{sample}.dflye.contigs.fa",
            res=res,
            sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/dflye_short_polish/contigs.fa",
            res=res,
            sample=both_samples,
        ),
        # kraken2 the illumina assembly
        expand(
            "{res}/{sample}/shovill_assembly/kraken.assembly",
            res=res,
            sample=short_sample_names,
        ),
        # kraken2 the long_only assembly
        expand(
            "{res}/{sample}/dflye/dflye.assembly",
            res=res,
            sample=long_sample_names,
        ),
        # MRCA ref per illumina sample
        expand(
            "{res}/{sample}/{sample}.MRCA.csv",
            res=res,
            sample=short_sample_names,
        ),
        # MRCA ref per long sample
        expand(
            "{res}/{sample}/{sample}.long.MRCA.csv",
            res=res,
            sample=long_only_sample_names,
        ),
        # MLST ref per illumina sample
        expand(
            "{res}/{sample}/{sample}.MLST.csv",
            res=res,
            sample=short_sample_names,
        ),
         # MLST ref per long_only sample
        expand(
            "{res}/{sample}/{sample}.long.MLST.csv",
            res=res,
            sample=long_sample_names,
        ),
        # determine the basic Erm(41) status with TBLASTN in short sample
        expand(
             "{res}/{sample}/{sample}.erm41.status",
             res=res,
             sample=short_sample_names,
        ),
        # determine the basec Erm(41) satus with TBLASTN in long samples
        expand(
            "{res}/{sample}/{sample}.long.erm41.status",
            res=res,
            sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/ref_mapping/mabs/merged.sorted.bam",
            res=res, sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/ref_mapping/mabs/merged.sorted.depth.gz",
            res=res, sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/ref_mapping/mabs/longmerged.sorted.bam",
            res=res, sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/ref_mapping/mabs/longmerged.sorted.depth.gz",
            res=res, sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/{sample}.QC.csv",
            res=res,
            sample=list(set(list(short_sample_names + long_sample_names)))
        ),
        f"{res}/mashtree/assembly_mashtree.complete.tree",
        f"{res}/mashtree/assembly_mashtree.complete.matrix",
        f"{res}/QC_summary.csv",
        expand(
            "{res}/{sample}/{sample}.{dflye}.prokka.gff",
            res=res, sample=both_samples, dflye="dflye_short_polish"
        )

rule stage2_short:
    input:
        ##################################
        # STAGE 2 SHORT - type-specific analyses
        ##################################
        # temp file
        # [
        #     "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.merged.sorted.bam".format(
        #         res=res,
        #         ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
        #         sample=s,
        #     ) for s in filt_short_samples
        # ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.mpileup".format(
                res=res,
                ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.vcf.gz".format(
                res=res,
                ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.AD_failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.hvar.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.0cov.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.lowcov.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.variants.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.mask.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.consensus.fa".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.hvar_DF.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_short_samples
        ],
        

rule stage2_long:
    input:
        ##################################
        # STAGE 2 LONG - type-specific analyses
        ##################################
        # temp file
        # [
        #     "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.longmerged.sorted.bam".format(
        #         res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", 'long'),
        #         sample=s,
        #     ) for s in filt_long_samples
        # ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.mpileup".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.long.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.long.failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.long.AD_failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.long.hvar.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.0cov.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.lowcov.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.variants.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.mask.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC.long.consensus.fa".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_filter.long.hvar_DF.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long"),
                sample=s
            ) for s in filt_long_samples
        ],

# gubbins_output = []
# gubbins = ['nogubbins']
# # TODO: this needs to be per-reference, ie a reference has to have at least 3
# # isolates assigned to it in order to be eligible for gubbins, otherwise
# # skip gubbins
# if len(list(set(list(filt_short_samples + filt_long_samples)))) >= 3:
#     gubbins_output += expand(
#         "{res}/gubbins/{ref}.gubbins.done",
#         res=res,
#         ref=(
#             ref_from_QC(s, f"{res}/QC_summary.csv")  for s in 
#             filt_short_samples + filt_long_samples
#         )
#     )
#     gubbins_output += expand(
#         "{res}/gubbins/{ref}.gubbins.bed",
#         res=res,
#         ref=(
#             ref_from_QC(s, f"{res}/QC_summary.csv") for s in 
#             filt_short_samples + filt_long_samples
#         )
#     )
#     gubbins_output += expand(
#         "{res}/MRCA_ref_mapping/{ref}/merge.gubbins.vcf.gz",
#         res=res,
#         ref=(
#             ref_from_QC(s, f"{res}/QC_summary.csv") for s in 
#             filt_short_samples + filt_long_samples
#         )
#     ),
#     gubbins += ['gubbins']

rule stage3_short_only:
    input:
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_only.fasta",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if 
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_only.gubbins.done",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_only.gubbins.bed",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),
        [
            "{res}/{s}/MRCA_ref_mapping/{ref}/"
            "RG_SC.short_only.combined.bed".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv")
            ) for s in filt_short_samples 
        ],
        # combined short_only masked consensus fasta per sample per reference
        [
            "{res}/{s}/MRCA_ref_mapping/{ref}/"
            "RG_SC.short_only.combined.consensus.fasta".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv")
            ) for s in filt_short_samples 
        ],
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_only.consensus.fasta",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_only.consensus.fasta.treefile",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_only.consensus.fasta.snpdists.csv",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ]
            ]
        ),


rule stage3_short_long:
    input:
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_long.fasta",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_long.gubbins.done",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),
        expand(
            "{res}/gubbins/{ref}.RG_SC.short_long.gubbins.bed",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),
        [
            "{res}/{s}/MRCA_ref_mapping/{ref}/RG_SC.short_long.combined.bed".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv")
            ) for s in filt_short_samples 
        ] + [
            "{res}/{s}/MRCA_ref_mapping/{ref}/RG_SC.short_long.long.combined.bed".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long")
            ) for s in filt_long_samples 
        ],
        # short_long combined consensus fasta per sample per reference
        [
            "{res}/{s}/MRCA_ref_mapping/{ref}/"
            "RG_SC.short_long.combined.consensus.fasta".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv")
            ) for s in filt_short_samples 
        ] + [
            "{res}/{s}/MRCA_ref_mapping/{ref}/"
            "RG_SC.short_long.long.combined.consensus.fasta".format(
                res=res, s=s, ref=ref_from_QC(s, f"{res}/QC_summary.csv", "long")
            ) for s in filt_long_samples 
        ],
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_long.consensus.fasta",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_long.consensus.fasta.treefile",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),
        expand(
            "{res}/SNP_phylo/{ref}.RG_SC.short_long.consensus.fasta.snpdists.csv",
            res=res, ref=[
                r for r in config['mash_ref_taxa'] if
                r in [
                    ref_from_QC(s, f"{res}/QC_summary.csv") for
                    s in filt_short_samples
                ] + [
                    ref_from_QC(s, f"{res}/QC_summary.csv", "long") for
                    s in filt_long_samples
                ]
            ]
        ),

# rule stage3:
#     input:
#         f"{res}/QC_summary.csv",
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.0cov.bed",
#             res=res,
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
#         ),
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.DF.bed",
#             res=res,
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
#         ),
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.bed",
#             res=res,
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
#         ),
#         [
#             "{res}/{sample}/filtered_vcf/{ref}/RG_SC_RA_bedfilter.vcf.gz".format(
#                 res=res,
#                 ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
#             ) for s in filt_samples
#         ],
#         [
#             "{res}/{sample}/filtered_vcf/{ref}/RG_SC_RA_bedfilter"
#             ".consensus.fasta".format(
#                 res=res,
#                 ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
#             ) for s in filt_samples
#         ],
#         [
#             "{res}/{sample}/gubbins/{ref}/RG_SC_RA_bedfilter_gubbins.fasta".format(
#                 res=res,
#                 ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
#             ) for s in filt_samples
#         ],
#         expand(
#             "{res}/gubbins/{ref}.concatenated.fasta",
#             res=res,
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         gubbins_output,
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.vcf.gz",
#             res=res, gubbins=['nogubbins', 'gubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.vcf.gz.csi",
#             res=res, gubbins=['nogubbins', 'gubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         expand(
#             "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta",
#             res=res, gubbins=['nogubbins', 'gubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         expand(
#             "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta.treefile",
#             res=res, gubbins=['nogubbins', 'gubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         expand(
#             "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta.snpdists.csv",
#             res=res, gubbins=['gubbins', 'nogubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
#         expand(
#             "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.snpeff.vcf",
#             res=res, gubbins=['gubbins', 'nogubbins'],
#             ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
#         ),
