# copyright 2022 nicholas.waglechner@sinaihealth.ca
import sys
import os
import pandas as pd
import glob

# add to command line to be explicit --configfile: ./config/config.yaml"
if len(config) == 0:
    exit('no configfile specified: use --configfile [file]')

config_path = sys.argv[sys.argv.index('--configfile') + 1]
print(f"using config: {config_path}", file=sys.stderr)

container: "docker://continuumio/miniconda3:4.9.2"

"""
from https://snakemake.readthedocs.io/en/v5.22.1/snakefiles/configuration.html#validation
""" # noqa
# validate(config, "config.schema.yaml")
# validate(samples, "samples.schema.yaml")

# TODO -- from
"""
https://charlesreid1.github.io/building-snakemake-command-line-wrappers-for-workflows.html
""" # noqa

exec_dir = os.getcwd()
res = config['results_dir']

include: "common.smk"

samples = get_samples()
sample_names = samples.keys()
# TODO this is kind of lazy, and could use some more checks to ensure there are
# paired R1 and R2 for each sample
short_sample_names = [n for n in sample_names if len(samples[n]['MISEQ']['R1']) > 0]
long_sample_names = [n for n in sample_names if len(samples[n]['MINION']) > 0]
short_only_sample_names = [
    n for n in short_sample_names if n not in long_sample_names
]
long_only_sample_names = [
    n for n in long_sample_names if n not in short_sample_names
]
both_samples = [
    n for n in sample_names if 
    n in short_sample_names and 
    n in long_sample_names
]
# sample_names = list(sample_names)[:20]
print("short samples:", sample_names, file=sys.stderr)
print("long samples:", long_sample_names, file=sys.stderr)
print("both sample names:", both_samples, file=sys.stderr)

filt_samples = list(sample_names)
filtered_samples = config['exclude_samples']
for name in filtered_samples:
    try:
        filt_samples.remove(name)
    except Exception as e:
        print(
            'tried to_exclude {}, not found in sample_sheet'.format(name),
            file=sys.stderr
        )
print('Including {} isolates (from original {} isolates)'.format(
    len(filt_samples), len(sample_names)
))

# medaka parsing to turn off
if config['dflye_medaka'] < 1:
    config['_DFLYE_MEDAKA'] = ""
else:
    config['_DFLYE_MEDAKA'] = f" --medaka {config['dflye_medaka']} " \
        f"--model {config['dflye_medaka_model']} " \
        f"--medaka_opts \'{config['dflye_medaka_opts']}\' "

# external data rules + GATK initialization
include: "stage0.smk"

# Illumina-QC pipeline
include: "stage1.smk"
# # variant calling
include: "stage2.smk"
# # variant counting
include: "stage3.smk"
# include: "SNP_counts.smk"


rule all:

# Rule "all" default catches output of other rules as input in order to
# simplify running the workflow
# - add target rules here as they are implemented

rule stage1:
    input:
        ###############
        # STAGE 1 - QC
        ###############
        f"{res}/QC_summary.csv"

rule stage1_all_outputs:
    input:
        # pre-trim QC
        expand(
            "{res}/{sample}/input/{R}_fastqc.html",
            res=res,
            sample=short_sample_names,
            R=["R1", "R2"],
        ),
        # trimmed input
        expand(
            "{res}/{s}/input/{read}.trim.fastq.gz",
            res=res,
            s=short_sample_names,
            read=["R1", "R2", "S1", "S2"],
        ),
        # post-trim QC
        expand(
            "{res}/{s}/input/{read}.trim_fastqc.data.txt",
            res=res,
            s=short_sample_names,
            read=["R1", "R2", "S1", "S2"],
        ),
        expand(
            "{res}/{s}/input/{read}_fastqc.data.txt",
            res=res,
            s=short_sample_names,
            read=["R1", "R2"],
        ),
        expand(
            "{res}/{s}/input/long_fastqc.data.txt",
            res=res,
            s=long_sample_names,
        ),
        # Kraken contamination, paired and single
        expand(
            "{res}/{sample}/input/kraken.trimmed.paired",
            res=res,
            sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/input/kraken.trimmed.single",
            res=res,
            sample=short_sample_names,
        ),
        # assembly with shovill
        expand(
            "{res}/{sample}/shovill_assembly/{sample}.shovill.contigs.fa",
            res=res,
            sample=short_sample_names,
        ),
        expand(
            "{res}/{sample}/dflye/contigs.fa",
            res=res,
            sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/dflye_short_polish/contigs.fa",
            res=res,
            sample=both_samples,
        ),
        # kraken2 the illumina assembly
        expand(
            "{res}/{sample}/shovill_assembly/kraken.assembly",
            res=res,
            sample=short_sample_names,
        ),
        # kraken2 the long_only assembly
        expand(
            "{res}/{sample}/dflye/contigs.fa",
            res=res,
            sample=long_sample_names,
        ),
        # MRCA ref per illumina sample
        expand(
            "{res}/{sample}/{sample}.MRCA.csv",
            res=res,
            sample=short_sample_names,
        ),
        # MRCA ref per long sample
        expand(
            "{res}/{sample}/{sample}.long.MRCA.csv",
            res=res,
            sample=long_only_sample_names,
        ),
        # MLST ref per illumina sample
        expand(
            "{res}/{sample}/{sample}.MLST.csv",
            res=res,
            sample=short_sample_names,
        ),
        # MLST ref per long_only sample
        expand(
            "{res}/{sample}/{sample}.long.MLST.csv",
            res=res,
            sample=long_sample_names,
        ),
        # determine the basic Erm(41) status with TBLASTN in short sample
        expand(
            "{res}/{sample}/{sample}.erm41.status",
            res=res,
            sample=short_sample_names,
        ),
        # determine the basec Erm(41) satus with TBLASTN in long samples
        expand(
            "{res}/{sample}/{sample}.long.erm41.status",
            res=res,
            sample=long_sample_names,
        ),
        expand(
            "{res}/{sample}/{sample}.QC.csv",
            res=res,
            sample=sample_names
        ),
        f"{res}/mashtree/assembly_mashtree.complete.tree",
        f"{res}/mashtree/assembly_mashtree.complete.matrix",
        f"{res}/QC_summary.csv",
        expand(
            "{res}/{sample}/{sample}.{dflye}.prokka.gff",
            res=res, sample=both_samples, dflye="dflye_short_polish"
        )

rule stage2:
    input:
        ##################################
        # STAGE 2 - type-specific analyses
        ##################################
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA.intervals".format(
                 res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA.bam".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s,
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA.mpileup".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA_filter.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA_filter.failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA_filter.AD_failed.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA_filter.hvar.vcf.gz".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA.0cov.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/MRCA_ref_mapping/{ref}/RG_SC_RA_filter.hvar_DF.bed".format(
                res=res, ref=ref_from_QC(s, f"{res}/QC_summary.csv"),
                sample=s
            ) for s in filt_samples
        ],


gubbins_output = []
gubbins = ['nogubbins']
# TODO: this needs to be per-reference, ie a reference has to have at least 3
# isolates assigned to it in order to be eligible for gubbins, otherwise
# skip gubbins
if len(filt_samples) >= 3:
    gubbins_output += expand(
        "{res}/gubbins/{ref}.gubbins.done",
        res=res,
        ref=(ref_from_QC(s, f"{res}/QC_summary.csv")  for s in filt_samples)
    )
    gubbins_output += expand(
        "{res}/gubbins/{ref}.gubbins.bed",
        res=res,
        ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
    )
    gubbins_output += expand(
        "{res}/MRCA_ref_mapping/{ref}/merge.gubbins.vcf.gz",
        res=res,
        ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
    ),
    gubbins += ['gubbins']


rule stage3:
    input:
        f"{res}/QC_summary.csv",
        expand(
            "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.0cov.bed",
            res=res,
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
        ),
        expand(
            "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.DF.bed",
            res=res,
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
        ),
        expand(
            "{res}/MRCA_ref_mapping/{ref}/RG_SC_RA.merge.bed",
            res=res,
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples),
        ),
        [
            "{res}/{sample}/filtered_vcf/{ref}/RG_SC_RA_bedfilter.vcf.gz".format(
                res=res,
                ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/filtered_vcf/{ref}/RG_SC_RA_bedfilter"
            ".consensus.fasta".format(
                res=res,
                ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
            ) for s in filt_samples
        ],
        [
            "{res}/{sample}/gubbins/{ref}/RG_SC_RA_bedfilter_gubbins.fasta".format(
                res=res,
                ref=ref_from_QC(s, f"{res}/QC_summary.csv"), sample=s
            ) for s in filt_samples
        ],
        expand(
            "{res}/gubbins/{ref}.concatenated.fasta",
            res=res,
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        gubbins_output,
        expand(
            "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.vcf.gz",
            res=res, gubbins=['nogubbins', 'gubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        expand(
            "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.vcf.gz.csi",
            res=res, gubbins=['nogubbins', 'gubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        expand(
            "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta",
            res=res, gubbins=['nogubbins', 'gubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        expand(
            "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta.treefile",
            res=res, gubbins=['nogubbins', 'gubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        expand(
            "{res}/SNP_phylo/{ref}.merge.{gubbins}.fasta.snpdists.csv",
            res=res, gubbins=['gubbins', 'nogubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
        expand(
            "{res}/MRCA_ref_mapping/{ref}/merge.{gubbins}.snpeff.vcf",
            res=res, gubbins=['gubbins', 'nogubbins'],
            ref=(ref_from_QC(s, f"{res}/QC_summary.csv") for s in filt_samples)
        ),
